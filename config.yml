# parameters.yml

default:

  # chunk up house price data set to read in due to size
  chunksize: 100000

  # set size of dev and test set
  dev_size: 10000
  test_size: 10000

  # output variable column name
  target_var: 'ln_price'
  
  # and drop id cols
  cols_out:
    - 'transactionid'
    - 'postcode'

  # outline each spatial attribute and the associated file
  # used to calculate distance from postcode to attribute
  spatial_dict:
    coastline:
      folder: "processed_inputs"
      file: "coastline.shp"

    prim_school:
      folder: "processed_inputs"
      file: "primary_school.shp"

    sec_school:
      folder: "processed_inputs"
      file: "secondary_school.shp"
    
    roads:
      folder: "processed_inputs"
      file: "roads_c.shp"

    nat_park:
      folder: "raw_inputs"
      file: "National_Parks_(England)___Natural_England.shp"

    nat_trust:
      folder: "raw_inputs"
      file: "NT_Land_Always_Open.shp"
    
    ttwa:
      folder: "raw_inputs"
      file: "TTWA_Dec_2001_UGCB_in_the_UK.shp"
  
  # column names in ML dataset which are not normalised
  non_norm_cols:
    - 'transactionid'
    - 'ln_price'
    - 'postcode'
    - 'propertype'
    - 'oldnew'
    - 'duration'
    - 'construction_age_band'


  pre_processing:
  # TODO get func to be interpreted as a function in python
    postcodes:
      file_name: 'postcodes_c.shp'
      func: concat_postcodes

    roads:
      file_name: 'roads_c.shp'
      func: concat_roads
    
    coastline:
      file_name: 'coastline.shp'
      func: make_coastline

    mapped_postcodes:
      processed_file: 'mapped_postcodes.shp'

  # used to check if processing has already happened
  house_prices:
    processed_file: 'house_prices_c.csv'

  spatial_attributes:
    processed_file: 'spatial_attributes_c.csv'