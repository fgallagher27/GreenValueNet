{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenValueNet\n",
    "\n",
    "This notebook contains the code needed to execute the GreenValueNet hedonic pricing neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from data_load_funcs import get_params, load_data_catalogue\n",
    "from processing_funcs import process_data, normalise_values\n",
    "from model_funcs import *\n",
    "\n",
    "params = get_params()\n",
    "data_catalogue = load_data_catalogue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have a file called `dataset.csv` in the `data/interim_files` folder the following cell will generate this folder and generate summary statistics. The data processing happens locally and invovles large datasets with spatial components so can take quite several hours - please be pateint! If you already have the file, it will be read in and summary statistics are generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = process_data(data_catalogue, params)\n",
    "\n",
    "# show summary stats\n",
    "summary_stats = dataset.describe().transpose()[['mean', 'std', 'max', 'min']]\n",
    "summary_stats.columns = ['Mean', 'Std Dev', 'Maximum', 'Minimum']\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we normalise any non-encoded variables to increase speed of learning of algorithm and convert the dataset to an array of inputs, and an associated output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cols = [col for col in dataset.columns if col not in params['non_norm_cols']]\n",
    "for col in norm_cols:\n",
    "    dataset[col] = normalise_values(dataset[col])\n",
    "\n",
    "# creates an arry of shape m, x, y\n",
    "x, y = create_x_y_arr(dataset, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is then split into train, dev and test sets using sci-kit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_dev, x_test, y_train, y_dev, y_test = split_to_test_dev_train(\n",
    "    x,\n",
    "    y,\n",
    "    params['dev_size'],\n",
    "    params['test_size'],\n",
    "    prop=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "\n",
    "To evaluate the performance of my neural network I will run random forest and XGBoost regressions as baseline models. I will then build 2 alternative models: a deep neural network and a bayesian model. We optimise based on the mean squared error (MSE) but and report this as our measure of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run baseline random forest regression using scikit-learn\n",
    "rfr_model = random_forest_reg(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    tuning=False\n",
    ")\n",
    "\n",
    "# now run with grid search to tune parameters\n",
    "rfr_tuned  =  random_forest_reg(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    tuning=True,\n",
    "    tuning_params = params['tuning_dict']['grid']\n",
    ")\n",
    "\n",
    "# generate predictions and measure according to mean squared error\n",
    "rfr_pred, rfr_mse = generate_pred_metric(rfr_model, mean_squared_error, x_dev, y_dev)\n",
    "rfr_t_pred, rfr_t_mse = generate_pred_metric(rfr_tuned, mean_squared_error, x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = boosted_grad_reg(x_train, y_train)\n",
    "xgb_pred, xgb_mse = generate_pred_metric(xgb_model, mean_squared_error, x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "We know build some neural networks. Number of epochs, hidden layers, and nodes in hidden layers is initially set with rules of thumb but then optimiszed using hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set epochs to be 3 times number of features\n",
    "epochs = int(x_train.shape[1]) * 3\n",
    "\n",
    "# set n_hidden_units to be mean of input and output layer sizes\n",
    "n_hidden_units = round((x_train.shape[1] + 1) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Neural Network\n",
    "\n",
    "A single hidden layer with ReLU activation is used with a linear output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "4/4 [==============================] - 1s 96ms/step - loss: 136.3968 - mean_squared_error: 136.3968 - val_loss: 85.3140 - val_mean_squared_error: 85.3140\n",
      "Epoch 2/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 46.1918 - mean_squared_error: 46.1918 - val_loss: 14.7610 - val_mean_squared_error: 14.7610\n",
      "Epoch 3/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 16.5098 - mean_squared_error: 16.5098 - val_loss: 24.5878 - val_mean_squared_error: 24.5878\n",
      "Epoch 4/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 24.6024 - mean_squared_error: 24.6024 - val_loss: 9.8073 - val_mean_squared_error: 9.8073\n",
      "Epoch 5/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.9552 - mean_squared_error: 5.9552 - val_loss: 15.4586 - val_mean_squared_error: 15.4586\n",
      "Epoch 6/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 10.5398 - mean_squared_error: 10.5398 - val_loss: 17.0714 - val_mean_squared_error: 17.0714\n",
      "Epoch 7/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8.0101 - mean_squared_error: 8.0101 - val_loss: 7.9961 - val_mean_squared_error: 7.9961\n",
      "Epoch 8/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6184 - mean_squared_error: 2.6184 - val_loss: 4.7989 - val_mean_squared_error: 4.7989\n",
      "Epoch 9/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.1861 - mean_squared_error: 4.1861 - val_loss: 4.5081 - val_mean_squared_error: 4.5081\n",
      "Epoch 10/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.4716 - mean_squared_error: 2.4716 - val_loss: 3.8094 - val_mean_squared_error: 3.8094\n",
      "Epoch 11/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.7421 - mean_squared_error: 1.7421 - val_loss: 5.1419 - val_mean_squared_error: 5.1419\n",
      "Epoch 12/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2516 - mean_squared_error: 2.2516 - val_loss: 3.9497 - val_mean_squared_error: 3.9497\n",
      "Epoch 13/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3062 - mean_squared_error: 1.3062 - val_loss: 2.7980 - val_mean_squared_error: 2.7980\n",
      "Epoch 14/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.6037 - mean_squared_error: 1.6037 - val_loss: 2.7513 - val_mean_squared_error: 2.7513\n",
      "Epoch 15/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3276 - mean_squared_error: 1.3276 - val_loss: 2.7388 - val_mean_squared_error: 2.7388\n",
      "Epoch 16/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1224 - mean_squared_error: 1.1224 - val_loss: 3.0743 - val_mean_squared_error: 3.0743\n",
      "Epoch 17/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1854 - mean_squared_error: 1.1854 - val_loss: 2.6849 - val_mean_squared_error: 2.6849\n",
      "Epoch 18/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9423 - mean_squared_error: 0.9423 - val_loss: 2.3512 - val_mean_squared_error: 2.3512\n",
      "Epoch 19/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0089 - mean_squared_error: 1.0089 - val_loss: 2.2858 - val_mean_squared_error: 2.2858\n",
      "Epoch 20/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8747 - mean_squared_error: 0.8747 - val_loss: 2.3897 - val_mean_squared_error: 2.3897\n",
      "Epoch 21/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8566 - mean_squared_error: 0.8566 - val_loss: 2.3491 - val_mean_squared_error: 2.3491\n",
      "Epoch 22/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8119 - mean_squared_error: 0.8119 - val_loss: 2.1690 - val_mean_squared_error: 2.1690\n",
      "Epoch 23/69\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7848 - mean_squared_error: 0.7848 - val_loss: 2.0243 - val_mean_squared_error: 2.0243\n",
      "Epoch 24/69\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7640 - mean_squared_error: 0.7640 - val_loss: 2.0093 - val_mean_squared_error: 2.0093\n",
      "Epoch 25/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7308 - mean_squared_error: 0.7308 - val_loss: 1.9252 - val_mean_squared_error: 1.9252\n",
      "Epoch 26/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7015 - mean_squared_error: 0.7015 - val_loss: 1.8525 - val_mean_squared_error: 1.8525\n",
      "Epoch 27/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6862 - mean_squared_error: 0.6862 - val_loss: 1.7929 - val_mean_squared_error: 1.7929\n",
      "Epoch 28/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6691 - mean_squared_error: 0.6691 - val_loss: 1.6963 - val_mean_squared_error: 1.6963\n",
      "Epoch 29/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6542 - mean_squared_error: 0.6542 - val_loss: 1.6409 - val_mean_squared_error: 1.6409\n",
      "Epoch 30/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6372 - mean_squared_error: 0.6372 - val_loss: 1.6238 - val_mean_squared_error: 1.6238\n",
      "Epoch 31/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6250 - mean_squared_error: 0.6250 - val_loss: 1.5406 - val_mean_squared_error: 1.5406\n",
      "Epoch 32/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6108 - mean_squared_error: 0.6108 - val_loss: 1.4903 - val_mean_squared_error: 1.4903\n",
      "Epoch 33/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5932 - mean_squared_error: 0.5932 - val_loss: 1.4852 - val_mean_squared_error: 1.4852\n",
      "Epoch 34/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5859 - mean_squared_error: 0.5859 - val_loss: 1.4260 - val_mean_squared_error: 1.4260\n",
      "Epoch 35/69\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5720 - mean_squared_error: 0.5720 - val_loss: 1.3928 - val_mean_squared_error: 1.3928\n",
      "Epoch 36/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5640 - mean_squared_error: 0.5640 - val_loss: 1.3802 - val_mean_squared_error: 1.3802\n",
      "Epoch 37/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5510 - mean_squared_error: 0.5510 - val_loss: 1.3252 - val_mean_squared_error: 1.3252\n",
      "Epoch 38/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5445 - mean_squared_error: 0.5445 - val_loss: 1.2910 - val_mean_squared_error: 1.2910\n",
      "Epoch 39/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5345 - mean_squared_error: 0.5345 - val_loss: 1.2532 - val_mean_squared_error: 1.2532\n",
      "Epoch 40/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5252 - mean_squared_error: 0.5252 - val_loss: 1.2570 - val_mean_squared_error: 1.2570\n",
      "Epoch 41/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5187 - mean_squared_error: 0.5187 - val_loss: 1.2317 - val_mean_squared_error: 1.2317\n",
      "Epoch 42/69\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5071 - mean_squared_error: 0.5071 - val_loss: 1.1919 - val_mean_squared_error: 1.1919\n",
      "Epoch 43/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5149 - mean_squared_error: 0.5149 - val_loss: 1.1477 - val_mean_squared_error: 1.1477\n",
      "Epoch 44/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4977 - mean_squared_error: 0.4977 - val_loss: 1.1690 - val_mean_squared_error: 1.1690\n",
      "Epoch 45/69\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4964 - mean_squared_error: 0.4964 - val_loss: 1.1339 - val_mean_squared_error: 1.1339\n",
      "Epoch 46/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5128 - mean_squared_error: 0.5128 - val_loss: 1.0811 - val_mean_squared_error: 1.0811\n",
      "Epoch 47/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4721 - mean_squared_error: 0.4721 - val_loss: 1.1098 - val_mean_squared_error: 1.1098\n",
      "Epoch 48/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4819 - mean_squared_error: 0.4819 - val_loss: 1.0787 - val_mean_squared_error: 1.0787\n",
      "Epoch 49/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4634 - mean_squared_error: 0.4634 - val_loss: 1.0528 - val_mean_squared_error: 1.0528\n",
      "Epoch 50/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4571 - mean_squared_error: 0.4571 - val_loss: 1.0534 - val_mean_squared_error: 1.0534\n",
      "Epoch 51/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4538 - mean_squared_error: 0.4538 - val_loss: 1.0478 - val_mean_squared_error: 1.0478\n",
      "Epoch 52/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4451 - mean_squared_error: 0.4451 - val_loss: 1.0103 - val_mean_squared_error: 1.0103\n",
      "Epoch 53/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4431 - mean_squared_error: 0.4431 - val_loss: 0.9837 - val_mean_squared_error: 0.9837\n",
      "Epoch 54/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4371 - mean_squared_error: 0.4371 - val_loss: 0.9864 - val_mean_squared_error: 0.9864\n",
      "Epoch 55/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4392 - mean_squared_error: 0.4392 - val_loss: 0.9921 - val_mean_squared_error: 0.9921\n",
      "Epoch 56/69\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4253 - mean_squared_error: 0.4253 - val_loss: 0.9490 - val_mean_squared_error: 0.9490\n",
      "Epoch 57/69\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4220 - mean_squared_error: 0.4220 - val_loss: 0.9274 - val_mean_squared_error: 0.9274\n",
      "Epoch 58/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4267 - mean_squared_error: 0.4267 - val_loss: 0.9436 - val_mean_squared_error: 0.9436\n",
      "Epoch 59/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4169 - mean_squared_error: 0.4169 - val_loss: 0.9227 - val_mean_squared_error: 0.9227\n",
      "Epoch 60/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4121 - mean_squared_error: 0.4121 - val_loss: 0.8906 - val_mean_squared_error: 0.8906\n",
      "Epoch 61/69\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4090 - mean_squared_error: 0.4090 - val_loss: 0.9050 - val_mean_squared_error: 0.9050\n",
      "Epoch 62/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4064 - mean_squared_error: 0.4064 - val_loss: 0.8802 - val_mean_squared_error: 0.8802\n",
      "Epoch 63/69\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3969 - mean_squared_error: 0.3969 - val_loss: 0.8649 - val_mean_squared_error: 0.8649\n",
      "Epoch 64/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.8466 - val_mean_squared_error: 0.8466\n",
      "Epoch 65/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3918 - mean_squared_error: 0.3918 - val_loss: 0.8247 - val_mean_squared_error: 0.8247\n",
      "Epoch 66/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3880 - mean_squared_error: 0.3880 - val_loss: 0.8480 - val_mean_squared_error: 0.8480\n",
      "Epoch 67/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3904 - mean_squared_error: 0.3904 - val_loss: 0.8185 - val_mean_squared_error: 0.8185\n",
      "Epoch 68/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3784 - mean_squared_error: 0.3784 - val_loss: 0.8151 - val_mean_squared_error: 0.8151\n",
      "Epoch 69/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3761 - mean_squared_error: 0.3761 - val_loss: 0.8044 - val_mean_squared_error: 0.8044\n"
     ]
    }
   ],
   "source": [
    "single_nn = neural_net(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    n_hidden_units = n_hidden_units,\n",
    "    epochs = epochs,\n",
    "    validation_data = (x_dev, y_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [136.3968048095703,\n",
       "  46.19175720214844,\n",
       "  16.509822845458984,\n",
       "  24.60244369506836,\n",
       "  5.955211639404297,\n",
       "  10.539754867553711,\n",
       "  8.010050773620605,\n",
       "  2.6183974742889404,\n",
       "  4.186127185821533,\n",
       "  2.4716479778289795,\n",
       "  1.7420923709869385,\n",
       "  2.2516214847564697,\n",
       "  1.3061832189559937,\n",
       "  1.6037441492080688,\n",
       "  1.327576994895935,\n",
       "  1.1223970651626587,\n",
       "  1.1854450702667236,\n",
       "  0.9423322081565857,\n",
       "  1.0089224576950073,\n",
       "  0.8746951222419739,\n",
       "  0.8565689325332642,\n",
       "  0.8118577003479004,\n",
       "  0.7847859263420105,\n",
       "  0.764011800289154,\n",
       "  0.7308076024055481,\n",
       "  0.7014819979667664,\n",
       "  0.6861767172813416,\n",
       "  0.6691266298294067,\n",
       "  0.6542291641235352,\n",
       "  0.6371952891349792,\n",
       "  0.6249568462371826,\n",
       "  0.6107545495033264,\n",
       "  0.5932189226150513,\n",
       "  0.5858515501022339,\n",
       "  0.5719519257545471,\n",
       "  0.5639655590057373,\n",
       "  0.5509668588638306,\n",
       "  0.5444613695144653,\n",
       "  0.534468412399292,\n",
       "  0.5252289772033691,\n",
       "  0.5187070369720459,\n",
       "  0.5070637464523315,\n",
       "  0.5148545503616333,\n",
       "  0.4976750910282135,\n",
       "  0.4963563084602356,\n",
       "  0.5127622485160828,\n",
       "  0.472061425447464,\n",
       "  0.4819274842739105,\n",
       "  0.4634024500846863,\n",
       "  0.45706436038017273,\n",
       "  0.453757643699646,\n",
       "  0.4450613856315613,\n",
       "  0.44307830929756165,\n",
       "  0.4371468424797058,\n",
       "  0.4392099380493164,\n",
       "  0.4252944588661194,\n",
       "  0.42195937037467957,\n",
       "  0.426653116941452,\n",
       "  0.4169166386127472,\n",
       "  0.41207873821258545,\n",
       "  0.40898746252059937,\n",
       "  0.4064016342163086,\n",
       "  0.39690962433815,\n",
       "  0.3945246636867523,\n",
       "  0.3917694687843323,\n",
       "  0.3879866600036621,\n",
       "  0.39040902256965637,\n",
       "  0.37835535407066345,\n",
       "  0.3761278986930847],\n",
       " 'mean_squared_error': [136.3968048095703,\n",
       "  46.19175720214844,\n",
       "  16.509822845458984,\n",
       "  24.60244369506836,\n",
       "  5.955211639404297,\n",
       "  10.539754867553711,\n",
       "  8.010050773620605,\n",
       "  2.6183974742889404,\n",
       "  4.186127185821533,\n",
       "  2.4716479778289795,\n",
       "  1.7420923709869385,\n",
       "  2.2516214847564697,\n",
       "  1.3061832189559937,\n",
       "  1.6037441492080688,\n",
       "  1.327576994895935,\n",
       "  1.1223970651626587,\n",
       "  1.1854450702667236,\n",
       "  0.9423322081565857,\n",
       "  1.0089224576950073,\n",
       "  0.8746951222419739,\n",
       "  0.8565689325332642,\n",
       "  0.8118577003479004,\n",
       "  0.7847859263420105,\n",
       "  0.764011800289154,\n",
       "  0.7308076024055481,\n",
       "  0.7014819979667664,\n",
       "  0.6861767172813416,\n",
       "  0.6691266298294067,\n",
       "  0.6542291641235352,\n",
       "  0.6371952891349792,\n",
       "  0.6249568462371826,\n",
       "  0.6107545495033264,\n",
       "  0.5932189226150513,\n",
       "  0.5858515501022339,\n",
       "  0.5719519257545471,\n",
       "  0.5639655590057373,\n",
       "  0.5509668588638306,\n",
       "  0.5444613695144653,\n",
       "  0.534468412399292,\n",
       "  0.5252289772033691,\n",
       "  0.5187070369720459,\n",
       "  0.5070637464523315,\n",
       "  0.5148545503616333,\n",
       "  0.4976750910282135,\n",
       "  0.4963563084602356,\n",
       "  0.5127622485160828,\n",
       "  0.472061425447464,\n",
       "  0.4819274842739105,\n",
       "  0.4634024500846863,\n",
       "  0.45706436038017273,\n",
       "  0.453757643699646,\n",
       "  0.4450613856315613,\n",
       "  0.44307830929756165,\n",
       "  0.4371468424797058,\n",
       "  0.4392099380493164,\n",
       "  0.4252944588661194,\n",
       "  0.42195937037467957,\n",
       "  0.426653116941452,\n",
       "  0.4169166386127472,\n",
       "  0.41207873821258545,\n",
       "  0.40898746252059937,\n",
       "  0.4064016342163086,\n",
       "  0.39690962433815,\n",
       "  0.3945246636867523,\n",
       "  0.3917694687843323,\n",
       "  0.3879866600036621,\n",
       "  0.39040902256965637,\n",
       "  0.37835535407066345,\n",
       "  0.3761278986930847],\n",
       " 'val_loss': [85.31404113769531,\n",
       "  14.761016845703125,\n",
       "  24.587770462036133,\n",
       "  9.807256698608398,\n",
       "  15.458569526672363,\n",
       "  17.071399688720703,\n",
       "  7.996082305908203,\n",
       "  4.798859596252441,\n",
       "  4.508143424987793,\n",
       "  3.809401273727417,\n",
       "  5.14185094833374,\n",
       "  3.9496874809265137,\n",
       "  2.7979979515075684,\n",
       "  2.751303195953369,\n",
       "  2.7387588024139404,\n",
       "  3.074329376220703,\n",
       "  2.6849498748779297,\n",
       "  2.3511884212493896,\n",
       "  2.2858266830444336,\n",
       "  2.3897106647491455,\n",
       "  2.349062442779541,\n",
       "  2.1689767837524414,\n",
       "  2.0242974758148193,\n",
       "  2.009320020675659,\n",
       "  1.9252231121063232,\n",
       "  1.8525488376617432,\n",
       "  1.7929216623306274,\n",
       "  1.6962871551513672,\n",
       "  1.6409366130828857,\n",
       "  1.623757004737854,\n",
       "  1.540557861328125,\n",
       "  1.4902607202529907,\n",
       "  1.4852378368377686,\n",
       "  1.4259570837020874,\n",
       "  1.3928405046463013,\n",
       "  1.3801687955856323,\n",
       "  1.3251954317092896,\n",
       "  1.2910444736480713,\n",
       "  1.2531553506851196,\n",
       "  1.256996512413025,\n",
       "  1.2316789627075195,\n",
       "  1.19187331199646,\n",
       "  1.1476889848709106,\n",
       "  1.1690367460250854,\n",
       "  1.1339229345321655,\n",
       "  1.0811268091201782,\n",
       "  1.1097567081451416,\n",
       "  1.0786927938461304,\n",
       "  1.0527904033660889,\n",
       "  1.053365707397461,\n",
       "  1.0477659702301025,\n",
       "  1.010317087173462,\n",
       "  0.9837409853935242,\n",
       "  0.9863952398300171,\n",
       "  0.9921337962150574,\n",
       "  0.9490415453910828,\n",
       "  0.9273784756660461,\n",
       "  0.94361811876297,\n",
       "  0.9227313995361328,\n",
       "  0.890609085559845,\n",
       "  0.9049670100212097,\n",
       "  0.880192756652832,\n",
       "  0.8649035692214966,\n",
       "  0.8466024398803711,\n",
       "  0.8247421979904175,\n",
       "  0.8479677438735962,\n",
       "  0.8184892535209656,\n",
       "  0.8150514364242554,\n",
       "  0.8044182658195496],\n",
       " 'val_mean_squared_error': [85.31404113769531,\n",
       "  14.761016845703125,\n",
       "  24.587770462036133,\n",
       "  9.807256698608398,\n",
       "  15.458569526672363,\n",
       "  17.071399688720703,\n",
       "  7.996082305908203,\n",
       "  4.798859596252441,\n",
       "  4.508143424987793,\n",
       "  3.809401273727417,\n",
       "  5.14185094833374,\n",
       "  3.9496874809265137,\n",
       "  2.7979979515075684,\n",
       "  2.751303195953369,\n",
       "  2.7387588024139404,\n",
       "  3.074329376220703,\n",
       "  2.6849498748779297,\n",
       "  2.3511884212493896,\n",
       "  2.2858266830444336,\n",
       "  2.3897106647491455,\n",
       "  2.349062442779541,\n",
       "  2.1689767837524414,\n",
       "  2.0242974758148193,\n",
       "  2.009320020675659,\n",
       "  1.9252231121063232,\n",
       "  1.8525488376617432,\n",
       "  1.7929216623306274,\n",
       "  1.6962871551513672,\n",
       "  1.6409366130828857,\n",
       "  1.623757004737854,\n",
       "  1.540557861328125,\n",
       "  1.4902607202529907,\n",
       "  1.4852378368377686,\n",
       "  1.4259570837020874,\n",
       "  1.3928405046463013,\n",
       "  1.3801687955856323,\n",
       "  1.3251954317092896,\n",
       "  1.2910444736480713,\n",
       "  1.2531553506851196,\n",
       "  1.256996512413025,\n",
       "  1.2316789627075195,\n",
       "  1.19187331199646,\n",
       "  1.1476889848709106,\n",
       "  1.1690367460250854,\n",
       "  1.1339229345321655,\n",
       "  1.0811268091201782,\n",
       "  1.1097567081451416,\n",
       "  1.0786927938461304,\n",
       "  1.0527904033660889,\n",
       "  1.053365707397461,\n",
       "  1.0477659702301025,\n",
       "  1.010317087173462,\n",
       "  0.9837409853935242,\n",
       "  0.9863952398300171,\n",
       "  0.9921337962150574,\n",
       "  0.9490415453910828,\n",
       "  0.9273784756660461,\n",
       "  0.94361811876297,\n",
       "  0.9227313995361328,\n",
       "  0.890609085559845,\n",
       "  0.9049670100212097,\n",
       "  0.880192756652832,\n",
       "  0.8649035692214966,\n",
       "  0.8466024398803711,\n",
       "  0.8247421979904175,\n",
       "  0.8479677438735962,\n",
       "  0.8184892535209656,\n",
       "  0.8150514364242554,\n",
       "  0.8044182658195496]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_nn.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network\n",
    "\n",
    "The full model is specified as a deep neural network using layers with ReLU activation functions with a linear activation in the output layer. The choice of number of layers was initially kept small due to computational processing constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n",
      "4/4 [==============================] - 1s 82ms/step - loss: 100.1980 - mean_squared_error: 100.1980 - val_loss: 32.5866 - val_mean_squared_error: 32.5866\n",
      "Epoch 2/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 24.8172 - mean_squared_error: 24.8172 - val_loss: 28.3076 - val_mean_squared_error: 28.3076\n",
      "Epoch 3/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 11.7905 - mean_squared_error: 11.7905 - val_loss: 7.6204 - val_mean_squared_error: 7.6204\n",
      "Epoch 4/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.5939 - mean_squared_error: 5.5939 - val_loss: 9.1073 - val_mean_squared_error: 9.1073\n",
      "Epoch 5/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.1919 - mean_squared_error: 4.1919 - val_loss: 2.2644 - val_mean_squared_error: 2.2644\n",
      "Epoch 6/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8088 - mean_squared_error: 2.8088 - val_loss: 2.7438 - val_mean_squared_error: 2.7438\n",
      "Epoch 7/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.3185 - mean_squared_error: 2.3185 - val_loss: 1.7197 - val_mean_squared_error: 1.7197\n",
      "Epoch 8/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3877 - mean_squared_error: 1.3877 - val_loss: 1.4838 - val_mean_squared_error: 1.4838\n",
      "Epoch 9/69\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1001 - mean_squared_error: 1.1001 - val_loss: 2.4230 - val_mean_squared_error: 2.4230\n",
      "Epoch 10/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9771 - mean_squared_error: 0.9771 - val_loss: 1.4611 - val_mean_squared_error: 1.4611\n",
      "Epoch 11/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8321 - mean_squared_error: 0.8321 - val_loss: 1.9236 - val_mean_squared_error: 1.9236\n",
      "Epoch 12/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6501 - mean_squared_error: 0.6501 - val_loss: 1.2672 - val_mean_squared_error: 1.2672\n",
      "Epoch 13/69\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6664 - mean_squared_error: 0.6664 - val_loss: 1.4081 - val_mean_squared_error: 1.4081\n",
      "Epoch 14/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6022 - mean_squared_error: 0.6022 - val_loss: 1.0717 - val_mean_squared_error: 1.0717\n",
      "Epoch 15/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5150 - mean_squared_error: 0.5150 - val_loss: 1.1582 - val_mean_squared_error: 1.1582\n",
      "Epoch 16/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5354 - mean_squared_error: 0.5354 - val_loss: 0.9604 - val_mean_squared_error: 0.9604\n",
      "Epoch 17/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4946 - mean_squared_error: 0.4946 - val_loss: 1.0190 - val_mean_squared_error: 1.0190\n",
      "Epoch 18/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4909 - mean_squared_error: 0.4909 - val_loss: 0.9005 - val_mean_squared_error: 0.9005\n",
      "Epoch 19/69\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4286 - mean_squared_error: 0.4286 - val_loss: 0.8845 - val_mean_squared_error: 0.8845\n",
      "Epoch 20/69\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.8356 - val_mean_squared_error: 0.8356\n",
      "Epoch 21/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4203 - mean_squared_error: 0.4203 - val_loss: 0.8847 - val_mean_squared_error: 0.8847\n",
      "Epoch 22/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4317 - mean_squared_error: 0.4317 - val_loss: 0.7605 - val_mean_squared_error: 0.7605\n",
      "Epoch 23/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4160 - mean_squared_error: 0.4160 - val_loss: 0.8020 - val_mean_squared_error: 0.8020\n",
      "Epoch 24/69\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4064 - mean_squared_error: 0.4064 - val_loss: 0.7082 - val_mean_squared_error: 0.7082\n",
      "Epoch 25/69\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4109 - mean_squared_error: 0.4109 - val_loss: 0.7044 - val_mean_squared_error: 0.7044\n",
      "Epoch 26/69\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3675 - mean_squared_error: 0.3675 - val_loss: 0.7110 - val_mean_squared_error: 0.7110\n",
      "Epoch 27/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3858 - mean_squared_error: 0.3858 - val_loss: 0.6845 - val_mean_squared_error: 0.6845\n",
      "Epoch 28/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3635 - mean_squared_error: 0.3635 - val_loss: 0.7028 - val_mean_squared_error: 0.7028\n",
      "Epoch 29/69\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3454 - mean_squared_error: 0.3454 - val_loss: 0.6353 - val_mean_squared_error: 0.6353\n",
      "Epoch 30/69\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.6258 - val_mean_squared_error: 0.6258\n",
      "Epoch 31/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3490 - mean_squared_error: 0.3490 - val_loss: 0.6199 - val_mean_squared_error: 0.6199\n",
      "Epoch 32/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3363 - mean_squared_error: 0.3363 - val_loss: 0.6292 - val_mean_squared_error: 0.6292\n",
      "Epoch 33/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.5979 - val_mean_squared_error: 0.5979\n",
      "Epoch 34/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3423 - mean_squared_error: 0.3423 - val_loss: 0.5847 - val_mean_squared_error: 0.5847\n",
      "Epoch 35/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3162 - mean_squared_error: 0.3162 - val_loss: 0.6578 - val_mean_squared_error: 0.6578\n",
      "Epoch 36/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3747 - mean_squared_error: 0.3747 - val_loss: 0.5959 - val_mean_squared_error: 0.5959\n",
      "Epoch 37/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3938 - mean_squared_error: 0.3938 - val_loss: 0.5452 - val_mean_squared_error: 0.5452\n",
      "Epoch 38/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3368 - mean_squared_error: 0.3368 - val_loss: 0.5693 - val_mean_squared_error: 0.5693\n",
      "Epoch 39/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3345 - mean_squared_error: 0.3345 - val_loss: 0.5414 - val_mean_squared_error: 0.5414\n",
      "Epoch 40/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3030 - mean_squared_error: 0.3030 - val_loss: 0.6080 - val_mean_squared_error: 0.6080\n",
      "Epoch 41/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3170 - mean_squared_error: 0.3170 - val_loss: 0.5961 - val_mean_squared_error: 0.5961\n",
      "Epoch 42/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4042 - mean_squared_error: 0.4042 - val_loss: 0.5421 - val_mean_squared_error: 0.5421\n",
      "Epoch 43/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.6539 - val_mean_squared_error: 0.6539\n",
      "Epoch 44/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3690 - mean_squared_error: 0.3690 - val_loss: 0.5750 - val_mean_squared_error: 0.5750\n",
      "Epoch 45/69\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3621 - mean_squared_error: 0.3621 - val_loss: 0.6066 - val_mean_squared_error: 0.6066\n",
      "Epoch 46/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3490 - mean_squared_error: 0.3490 - val_loss: 0.5749 - val_mean_squared_error: 0.5749\n",
      "Epoch 47/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3195 - mean_squared_error: 0.3195 - val_loss: 0.5320 - val_mean_squared_error: 0.5320\n",
      "Epoch 48/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3055 - mean_squared_error: 0.3055 - val_loss: 0.5074 - val_mean_squared_error: 0.5074\n",
      "Epoch 49/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2854 - mean_squared_error: 0.2854 - val_loss: 0.4990 - val_mean_squared_error: 0.4990\n",
      "Epoch 50/69\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2729 - mean_squared_error: 0.2729 - val_loss: 0.5166 - val_mean_squared_error: 0.5166\n",
      "Epoch 51/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2652 - mean_squared_error: 0.2652 - val_loss: 0.5138 - val_mean_squared_error: 0.5138\n",
      "Epoch 52/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3002 - mean_squared_error: 0.3002 - val_loss: 0.5217 - val_mean_squared_error: 0.5217\n",
      "Epoch 53/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2754 - mean_squared_error: 0.2754 - val_loss: 0.4993 - val_mean_squared_error: 0.4993\n",
      "Epoch 54/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2684 - mean_squared_error: 0.2684 - val_loss: 0.4685 - val_mean_squared_error: 0.4685\n",
      "Epoch 55/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2704 - mean_squared_error: 0.2704 - val_loss: 0.4655 - val_mean_squared_error: 0.4655\n",
      "Epoch 56/69\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2831 - mean_squared_error: 0.2831 - val_loss: 0.4983 - val_mean_squared_error: 0.4983\n",
      "Epoch 57/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2537 - mean_squared_error: 0.2537 - val_loss: 0.4635 - val_mean_squared_error: 0.4635\n",
      "Epoch 58/69\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2812 - mean_squared_error: 0.2812 - val_loss: 0.4557 - val_mean_squared_error: 0.4557\n",
      "Epoch 59/69\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3125 - mean_squared_error: 0.3125 - val_loss: 0.5632 - val_mean_squared_error: 0.5632\n",
      "Epoch 60/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2947 - mean_squared_error: 0.2947 - val_loss: 0.4575 - val_mean_squared_error: 0.4575\n",
      "Epoch 61/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3111 - mean_squared_error: 0.3111 - val_loss: 0.4596 - val_mean_squared_error: 0.4596\n",
      "Epoch 62/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2765 - mean_squared_error: 0.2765 - val_loss: 0.4341 - val_mean_squared_error: 0.4341\n",
      "Epoch 63/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2670 - mean_squared_error: 0.2670 - val_loss: 0.4715 - val_mean_squared_error: 0.4715\n",
      "Epoch 64/69\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2924 - mean_squared_error: 0.2924 - val_loss: 0.5059 - val_mean_squared_error: 0.5059\n",
      "Epoch 65/69\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3076 - mean_squared_error: 0.3076 - val_loss: 0.4537 - val_mean_squared_error: 0.4537\n",
      "Epoch 66/69\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2817 - mean_squared_error: 0.2817 - val_loss: 0.4414 - val_mean_squared_error: 0.4414\n",
      "Epoch 67/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2559 - mean_squared_error: 0.2559 - val_loss: 0.4723 - val_mean_squared_error: 0.4723\n",
      "Epoch 68/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2421 - mean_squared_error: 0.2421 - val_loss: 0.4277 - val_mean_squared_error: 0.4277\n",
      "Epoch 69/69\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2668 - mean_squared_error: 0.2668 - val_loss: 0.4424 - val_mean_squared_error: 0.4424\n"
     ]
    }
   ],
   "source": [
    "deep_nn = neural_net(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    n_layers = 5,\n",
    "    n_hidden_units = n_hidden_units,\n",
    "    epochs = epochs,\n",
    "    validation_data = (x_dev, y_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as tensor object and stick in a folder called outputs\n",
    "model_dir = cwd / \"outputs\" / \"models\"\n",
    "deep_nn.export(model_dir / \"deep_nn.tf\") # check this file ending"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
